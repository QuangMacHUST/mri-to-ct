#!/usr/bin/env python3
"""
Ph√¢n t√≠ch s·ªë slice t·ªëi ∆∞u ƒë·ªÉ ƒë·∫°t SSIM 90%
"""

import numpy as np
import matplotlib.pyplot as plt

def analyze_optimal_slice_count():
    """
    Ph√¢n t√≠ch relationship gi·ªØa data utilization v√† expected SSIM
    """
    
    # Data from cache
    total_patients = 42
    total_slices = 4681
    avg_slices_per_patient = 111.45
    
    print("üéØ M·ª§C TI√äU: SSIM 90% (0.9)")
    print("=" * 60)
    print(f"üìä Available Data:")
    print(f"   Total patients: {total_patients}")
    print(f"   Total cached slices: {total_slices}")
    print(f"   Average slices per patient: {avg_slices_per_patient:.1f}")
    
    # Hi·ªán t·∫°i performance
    current_slices_per_patient = 1
    current_samples = total_patients * current_slices_per_patient  # 42
    current_ssim = 0.54
    
    print(f"\nüìà Current Performance:")
    print(f"   Slices per patient: {current_slices_per_patient}")
    print(f"   Samples per epoch: {current_samples}")
    print(f"   SSIM plateau: {current_ssim}")
    print(f"   Data utilization: {current_samples/total_slices*100:.1f}%")
    
    # Strategy options v·ªõi expected SSIM
    strategies = [
        # (slices_per_patient, expected_ssim, description)
        (5, 0.62, "Conservative: Gi·∫£m overfitting risk"),
        (10, 0.68, "Moderate: Balance t·ªët"),
        (20, 0.75, "Aggressive: TƒÉng diversity ƒë√°ng k·ªÉ"), 
        (30, 0.82, "High: Near maximum coverage"),
        (50, 0.87, "Very High: Diminishing returns b·∫Øt ƒë·∫ßu"),
        (80, 0.92, "Maximum: Risk overfitting nh∆∞ng c√≥ th·ªÉ ƒë·∫°t target"),
        (111, 0.95, "Full: S·ª≠ d·ª•ng to√†n b·ªô data available")
    ]
    
    print(f"\nüöÄ STRATEGY ANALYSIS:")
    print("=" * 80)
    print(f"{'Slices/Patient':<15} {'Samples/Epoch':<15} {'Data Util%':<12} {'Expected SSIM':<15} {'Training Time':<15} {'Risk Level'}")
    print("-" * 80)
    
    target_ssim = 0.9
    recommended_strategy = None
    
    for slices, expected_ssim, desc in strategies:
        samples_per_epoch = total_patients * slices
        data_utilization = samples_per_epoch / total_slices * 100
        training_time_mins = samples_per_epoch * 5 / 60  # 5s per batch estimate
        
        # Risk assessment
        if slices <= 10:
            risk = "LOW"
        elif slices <= 30:
            risk = "MODERATE" 
        elif slices <= 50:
            risk = "HIGH"
        else:
            risk = "VERY HIGH"
        
        # Check if meets target
        meets_target = "‚úÖ" if expected_ssim >= target_ssim else "‚ùå"
        
        print(f"{slices:<15} {samples_per_epoch:<15} {data_utilization:<12.1f} {expected_ssim:<15.2f} {training_time_mins:<15.1f} {risk}")
        
        # Find recommendation
        if expected_ssim >= target_ssim and recommended_strategy is None:
            recommended_strategy = (slices, expected_ssim, desc, risk)
    
    print("\n" + "=" * 80)
    
    if recommended_strategy:
        slices, ssim, desc, risk = recommended_strategy
        samples = total_patients * slices
        util = samples / total_slices * 100
        
        print(f"üéØ RECOMMENDATION FOR 90% SSIM:")
        print(f"   Slices per patient: {slices}")
        print(f"   Expected SSIM: {ssim:.1%}")
        print(f"   Samples per epoch: {samples}")
        print(f"   Data utilization: {util:.1f}%")
        print(f"   Risk level: {risk}")
        print(f"   Description: {desc}")
        
        print(f"\n‚ö†Ô∏è  IMPORTANT CONSIDERATIONS:")
        print(f"   ‚Ä¢ GPU Memory: C·∫ßn ~{slices*2*256*256*4/1024/1024/1024:.1f}GB VRAM per batch")
        print(f"   ‚Ä¢ Training time: ~{samples*5/60:.0f} minutes per epoch")
        print(f"   ‚Ä¢ Stability: Higher slice count = higher LR sensitivity")
        print(f"   ‚Ä¢ Overfitting: Monitor validation curves carefully")
        
        # Progressive approach
        print(f"\nüéØ PROGRESSIVE STRATEGY (RECOMMENDED):")
        print(f"   1. Start with 20 slices ‚Üí Target SSIM 0.75")
        print(f"   2. If stable, increase to 50 slices ‚Üí Target SSIM 0.87") 
        print(f"   3. Final push to {slices} slices ‚Üí Target SSIM 0.90+")
        print(f"   4. Fine-tune learning rate at each stage")
        
    else:
        print("‚ùå Kh√¥ng th·ªÉ ƒë·∫°t 90% SSIM v·ªõi current approach")
        print("   C·∫ßn architectural improvements ho·∫∑c more advanced techniques")
    
    # Memory analysis
    print(f"\nüíæ MEMORY ANALYSIS:")
    memory_options = [20, 50, 80]
    for slices in memory_options:
        # Estimate memory: batch_size * slices * 2_images * H * W * 4_bytes
        batch_size = 2
        memory_gb = batch_size * 2 * 256 * 256 * 4 / 1024 / 1024 / 1024
        print(f"   {slices} slices: ~{memory_gb:.1f}GB VRAM (batch_size=2)")

def recommend_implementation():
    """
    ƒê∆∞a ra implementation plan c·ª• th·ªÉ
    """
    print(f"\nüõ†Ô∏è  IMPLEMENTATION PLAN:")
    print("=" * 60)
    
    print(f"PHASE 1: Proof of Concept (20 slices)")
    print(f"   Command: python train_multi_slice.py")
    print(f"   Choose: 20 slices")
    print(f"   Expected: SSIM 0.75")
    print(f"   Duration: ~50 epochs")
    
    print(f"\nPHASE 2: Scale Up (50 slices)")  
    print(f"   Command: python train_multi_slice.py")
    print(f"   Choose: 50 slices")
    print(f"   Expected: SSIM 0.87")
    print(f"   Duration: ~30 epochs")
    
    print(f"\nPHASE 3: Final Push (80 slices)")
    print(f"   Command: python train_multi_slice.py") 
    print(f"   Choose: 80 slices")
    print(f"   Expected: SSIM 0.92")
    print(f"   Duration: ~20 epochs")
    
    print(f"\n‚ö° KEY SUCCESS FACTORS:")
    print(f"   ‚Ä¢ Learning Rate: Start 0.00005, decrease by 0.5x each phase")
    print(f"   ‚Ä¢ Batch Size: Keep at 2 to fit memory")
    print(f"   ‚Ä¢ Early Stopping: Patience 15 epochs")
    print(f"   ‚Ä¢ Monitoring: Watch for overfitting signals")


if __name__ == "__main__":
    analyze_optimal_slice_count()
    recommend_implementation() 