#!/usr/bin/env python3
"""
ðŸš€ MRI-to-CT CycleGAN Quick Start Script
Tá»± Ä‘á»™ng setup vÃ  verify environment cho training
"""

import subprocess
import sys
import os
import platform

def print_header(text):
    """Print header vá»›i format Ä‘áº¹p"""
    print("\n" + "="*60)
    print(f"ðŸŽ¯ {text}")
    print("="*60)

def run_command(cmd, check=True):
    """Cháº¡y command vÃ  return output"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, check=check)
        return result.stdout.strip(), result.stderr.strip()
    except subprocess.CalledProcessError as e:
        return None, e.stderr

def check_python_version():
    """Kiá»ƒm tra Python version"""
    print_header("KIá»‚M TRA PYTHON VERSION")
    
    version = sys.version_info
    print(f"Python version: {version.major}.{version.minor}.{version.micro}")
    
    if version.major < 3 or (version.major == 3 and version.minor < 8):
        print("âŒ Cáº§n Python 3.8 trá»Ÿ lÃªn!")
        return False
    else:
        print("âœ… Python version há»£p lá»‡")
        return True

def check_gpu():
    """Kiá»ƒm tra GPU vÃ  CUDA"""
    print_header("KIá»‚M TRA GPU & CUDA")
    
    # Check nvidia-smi
    stdout, stderr = run_command("nvidia-smi", check=False)
    if stdout is None:
        print("âŒ nvidia-smi khÃ´ng tÃ¬m tháº¥y. Cáº§n cÃ i NVIDIA driver!")
        return False
    
    print("âœ… NVIDIA driver detected")
    
    # Extract GPU info
    lines = stdout.split('\n')
    for line in lines:
        if 'GeForce' in line or 'RTX' in line or 'GTX' in line:
            gpu_info = line.split('|')[1].strip()
            print(f"GPU: {gpu_info}")
            break
    
    return True

def check_pytorch_cuda():
    """Kiá»ƒm tra PyTorch CUDA"""
    print_header("KIá»‚M TRA PYTORCH CUDA")
    
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"CUDA version: {torch.version.cuda}")
            print(f"GPU count: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            print("âœ… PyTorch CUDA setup hoÃ n háº£o!")
            return True
        else:
            print("âŒ PyTorch khÃ´ng detect Ä‘Æ°á»£c CUDA")
            return False
            
    except ImportError:
        print("âŒ PyTorch chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t")
        return False

def install_pytorch_cuda():
    """CÃ i Ä‘áº·t PyTorch vá»›i CUDA"""
    print_header("CÃ€I Äáº¶T PYTORCH CUDA")
    
    cmd = "pip install torch==2.2.2+cu121 torchvision==0.17.2+cu121 --index-url https://download.pytorch.org/whl/cu121"
    print(f"Running: {cmd}")
    
    stdout, stderr = run_command(cmd)
    if stdout is None:
        print(f"âŒ Lá»—i cÃ i PyTorch: {stderr}")
        return False
    else:
        print("âœ… PyTorch CUDA cÃ i Ä‘áº·t thÃ nh cÃ´ng!")
        return True

def install_dependencies():
    """CÃ i Ä‘áº·t dependencies"""
    print_header("CÃ€I Äáº¶T DEPENDENCIES")
    
    packages = [
        "nibabel", "SimpleITK", "opencv-python", "scikit-image", 
        "matplotlib", "tensorboard", "tqdm", "scipy", "pillow", 
        "pydicom", "numpy<2.0"
    ]
    
    for package in packages:
        print(f"Installing {package}...")
        stdout, stderr = run_command(f"pip install {package}", check=False)
        if stdout is None:
            print(f"âš ï¸  Warning: Failed to install {package}")
        else:
            print(f"âœ… {package} installed")
    
    print("âœ… Dependencies installation completed!")

def verify_installation():
    """Verify toÃ n bá»™ installation"""
    print_header("VERIFY INSTALLATION")
    
    # Test imports
    test_packages = [
        ("torch", "PyTorch"),
        ("torchvision", "TorchVision"), 
        ("nibabel", "NiBabel"),
        ("SimpleITK", "SimpleITK"),
        ("cv2", "OpenCV"),
        ("skimage", "Scikit-Image"),
        ("matplotlib", "Matplotlib"),
        ("tensorboard", "TensorBoard")
    ]
    
    for package, name in test_packages:
        try:
            __import__(package)
            print(f"âœ… {name}")
        except ImportError:
            print(f"âŒ {name} - Failed to import")
    
    # Test GPU tensor
    try:
        import torch
        if torch.cuda.is_available():
            x = torch.randn(10, 10).cuda()
            print("âœ… GPU tensor creation successful")
            del x
            torch.cuda.empty_cache()
        else:
            print("âŒ GPU tensor creation failed")
    except Exception as e:
        print(f"âŒ GPU test error: {e}")

def check_data_structure():
    """Kiá»ƒm tra cáº¥u trÃºc data"""
    print_header("KIá»‚M TRA DATA STRUCTURE")
    
    required_dirs = ["data/MRI", "data/CT", "src"]
    
    for dir_path in required_dirs:
        if os.path.exists(dir_path):
            print(f"âœ… {dir_path} exists")
            
            if dir_path.startswith("data"):
                files = [f for f in os.listdir(dir_path) if f.endswith('.nii.gz')]
                print(f"   Files: {len(files)} .nii.gz files")
        else:
            print(f"âŒ {dir_path} not found")
            if dir_path.startswith("data"):
                os.makedirs(dir_path, exist_ok=True)
                print(f"   Created {dir_path}")

def main():
    """Main function"""
    print("ðŸ¥ MRI-to-CT CycleGAN Quick Start Setup")
    print("=====================================")
    
    # 1. Check Python
    if not check_python_version():
        print("\nâŒ Setup failed: Python version khÃ´ng há»£p lá»‡")
        return
    
    # 2. Check GPU
    if not check_gpu():
        print("\nâŒ Setup failed: GPU/CUDA khÃ´ng kháº£ dá»¥ng")
        return
    
    # 3. Check hoáº·c install PyTorch
    if not check_pytorch_cuda():
        print("\nðŸ”§ CÃ i Ä‘áº·t PyTorch CUDA...")
        if not install_pytorch_cuda():
            print("\nâŒ Setup failed: KhÃ´ng thá»ƒ cÃ i PyTorch")
            return
        
        # Re-check sau khi cÃ i
        if not check_pytorch_cuda():
            print("\nâŒ Setup failed: PyTorch CUDA váº«n khÃ´ng hoáº¡t Ä‘á»™ng")
            return
    
    # 4. Install dependencies
    install_dependencies()
    
    # 5. Verify installation
    verify_installation()
    
    # 6. Check data structure
    check_data_structure()
    
    print_header("SETUP COMPLETED!")
    print("ðŸŽ‰ Environment setup thÃ nh cÃ´ng!")
    print("\nðŸ“‹ Next steps:")
    print("1. Copy data files vÃ o data/MRI/ vÃ  data/CT/")
    print("2. Run: python check_gpu.py")
    print("3. Run: cd src && python train.py")
    print("\nðŸ“Š Expected performance:")
    print("- GTX 1650: ~2 hours/epoch")
    print("- VRAM usage: ~0.7GB/4GB")
    print("- SSIM improvement: 0.12 â†’ 0.28+ in first epochs")

if __name__ == "__main__":
    main() 