# ğŸ”¥ CycleGAN Training vá»›i Cached Preprocessing

## Tá»•ng quan

ÄÃ£ **chá»‰nh sá»­a `src/train.py`** Ä‘á»ƒ sá»­ dá»¥ng **cached data loader** thay vÃ¬ preprocessing realtime. Training CycleGAN bÃ¢y giá» nhanh hÆ¡n **~450x** nhá» tÃ¡ch preprocessing ra khá»i training loop.

### ğŸ”„ Nhá»¯ng gÃ¬ Ä‘Ã£ thay Ä‘á»•i:

**TRÆ¯á»šC ÄÃ‚Y:**
```python
from data_loader import create_data_loaders

train_loader, val_loader = create_data_loaders(
    config['mri_dir'], config['ct_dir'], 
    config['batch_size'], config['train_split'], config['num_workers']
)
```

**BÃ‚Y GIá»œ:**
```python
from cached_data_loader import CachedDataLoaderManager

loader_manager = CachedDataLoaderManager(config['cache_dir'])
train_loader, val_loader = loader_manager.create_train_val_loaders(
    batch_size=config['batch_size'],
    train_split=config['train_split'], 
    num_workers=config['num_workers'],
    augmentation_prob=config['augmentation_prob']
)
```

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### 1. **CÃ¡ch Ä‘Æ¡n giáº£n nháº¥t - Cháº¡y toÃ n bá»™ pipeline:**

```bash
# Cháº¡y cáº£ preprocessing + CycleGAN training
python train_cyclegan_with_cache.py

# Hoáº·c custom directories
python train_cyclegan_with_cache.py \
    --mri_dir data/MRI \
    --ct_dir data/CT \
    --cache_dir preprocessed_cache
```

### 2. **Cháº¡y tá»«ng bÆ°á»›c:**

#### BÆ°á»›c 1: Preprocessing (má»™t láº§n duy nháº¥t)
```bash
# Táº¡o cache preprocessed data
python preprocess_and_cache.py --format h5
```

#### BÆ°á»›c 2: Training CycleGAN nhanh
```bash
# Training vá»›i cached data
cd src && python train.py
```

### 3. **CÃ¡c options khÃ¡c:**

```bash
# Chá»‰ preprocessing, khÃ´ng training
python train_cyclegan_with_cache.py --preprocessing_only

# Bá» qua preprocessing (dÃ¹ng cache cÃ³ sáºµn)
python train_cyclegan_with_cache.py --skip_preprocessing
```

## ğŸ“Š Hiá»‡u suáº¥t cáº£i thiá»‡n

### **Training speed comparison:**

**TRÆ¯á»šC (vá»›i preprocessing realtime):**
- Má»—i epoch: ~56.6 phÃºt (preprocessing 42 bá»‡nh nhÃ¢n má»—i láº§n)
- 100 epochs: ~94.4 giá»
- Batch size: 2 (giá»›i háº¡n bá»Ÿi preprocessing memory)

**SAU (vá»›i cached data):**
- Má»—i epoch: ~4-8 giÃ¢y (chá»‰ load cache + augmentation)
- 100 epochs: ~7-15 phÃºt
- Batch size: 4-6 (khÃ´ng bá»‹ giá»›i háº¡n preprocessing)

**ğŸš€ Speedup: 450x nhanh hÆ¡n!**

## âš™ï¸ Cáº¥u hÃ¬nh training Ä‘Ã£ tá»‘i Æ°u

File `src/train.py` Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t vá»›i:

```python
config = {
    # Data parameters - Sá»­ dá»¥ng cache
    'cache_dir': 'preprocessed_cache',  # Thay vÃ¬ mri_dir/ct_dir
    'batch_size': 4,                    # TÄƒng tá»« 2 lÃªn 4
    'num_workers': 2,                   # TÄƒng tá»« 0 lÃªn 2  
    'augmentation_prob': 0.8,           # XÃ¡c suáº¥t augmentation
    
    # Training parameters
    'num_epochs': 100,                  # CÃ³ thá»ƒ train nhiá»u hÆ¡n
    'save_freq': 5,                     # Save má»—i 5 epochs
    'sample_freq': 5,                   # Sample má»—i 5 epochs
}
```

## ğŸ”§ Cáº¥u trÃºc files

```
mri-to-ct/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                    # âœ… Modified for cached data
â”‚   â”œâ”€â”€ cached_data_loader.py       # âœ… Fast data loader
â”‚   â”œâ”€â”€ models.py                   # ğŸ”„ CycleGAN model (unchanged)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ preprocess_and_cache.py         # âœ… Preprocessing script
â”œâ”€â”€ train_cyclegan_with_cache.py    # âœ… Complete pipeline
â”œâ”€â”€ preprocessed_cache/             # ğŸ“ Cache directory
â”‚   â”œâ”€â”€ brain_001.h5
â”‚   â”œâ”€â”€ brain_002.h5
â”‚   â””â”€â”€ ...
â””â”€â”€ data/
    â”œâ”€â”€ MRI/
    â””â”€â”€ CT/
```

## ğŸ¯ Pipeline workflow

### **1. Preprocessing (má»™t láº§n):**
```
data/MRI + data/CT â†’ preprocess_and_cache.py â†’ preprocessed_cache/
```

**CÃ¡c bÆ°á»›c preprocessing Ä‘Æ°á»£c cache:**
1. N4 bias correction
2. Brain+skull mask creation
3. MRI-guided CT artifact removal
4. Outlier clipping
5. Intensity normalization
6. Brain ROI cropping
7. Resize to 256Ã—256
8. Range clamping [0,1]

### **2. Training (nhanh):**
```
preprocessed_cache/ â†’ cached_data_loader â†’ CycleGAN training
```

**Má»—i epoch chá»‰ lÃ m:**
1. Load preprocessed slices tá»« cache
2. Convert to [-1,1] range
3. **Data augmentation** (rotation, flip, intensity scaling)
4. Feed vÃ o CycleGAN model

## ğŸ’¡ Lá»£i Ã­ch chÃ­nh

### **ğŸš€ Performance:**
- **450x speedup** cho data loading
- **94.4 giá» â†’ 7-15 phÃºt** cho 100 epochs
- Batch size lá»›n hÆ¡n: 2 â†’ 4-6

### **ğŸ’¾ Memory & Storage:**
- Cache size: ~2-5GB cho 42 bá»‡nh nhÃ¢n
- Preprocessing chá»‰ lÃ m 1 láº§n
- Reusable cho nhiá»u experiments

### **ğŸ”„ Consistency:**
- Augmentation sau convert [-1,1] (thá»‘ng nháº¥t)
- Background fill = -1 cho rotation
- Same preprocessing quality

### **âš¡ Development:**
- Faster iteration cho hyperparameter tuning
- Quick testing vá»›i subset data
- Real-time monitoring

## ğŸ“ˆ Monitoring training

Training sáº½ hiá»ƒn thá»‹:

```
ğŸ“Š Äang táº¡o fast cached data loaders...
ğŸ“¦ Cache info:
   Total patients: 42
   Total slices: 1024
   Cache size: 3.2 MB
   Save format: h5
ğŸš€ Training sáº½ nhanh hÆ¡n ~450x so vá»›i preprocessing realtime!

âœ… Created cached data loaders:
   Training: 819 slices
   Validation: 205 slices
   Batch size: 4
   Num workers: 2

ğŸš€ Báº¯t Ä‘áº§u training vá»›i cached preprocessed data...
   - Preprocessing Ä‘Ã£ Ä‘Æ°á»£c cache trÆ°á»›c
   - Má»—i epoch chá»‰ cáº§n load cache + augmentation
   - Augmentation Ä‘Æ°á»£c Ã¡p dá»¥ng sau khi convert vá» [-1,1]
   - Batch size cÃ³ thá»ƒ lá»›n hÆ¡n: 4

Epoch 1/100 - Time: 4.2s
Train Loss: 0.8234 | Val Loss: 0.7543
```

## ğŸ” Troubleshooting

### **Cache not found:**
```bash
âŒ Cache directory not found: preprocessed_cache
   Run: python preprocess_and_cache.py first!
```
**Solution:** Cháº¡y preprocessing trÆ°á»›c:
```bash
python preprocess_and_cache.py
```

### **Memory issues:**
Giáº£m batch_size trong `src/train.py`:
```python
'batch_size': 2,  # Thay vÃ¬ 4
'num_workers': 1, # Thay vÃ¬ 2
```

### **Training quÃ¡ nhanh:**
ÄÃ¢y lÃ  **bÃ¬nh thÆ°á»ng**! Cached training nhanh hÆ¡n ráº¥t nhiá»u.

## ğŸ‰ Káº¿t quáº£

Vá»›i cached preprocessing:

### **Time savings:**
- **Preprocessing:** 30 phÃºt (chá»‰ 1 láº§n) thay vÃ¬ 56.6 phÃºt/epoch
- **Training 100 epochs:** 15 phÃºt thay vÃ¬ 94.4 giá»
- **Total time saved:** ~94 giá»

### **Quality maintained:**
- Same preprocessing pipeline
- Better augmentation consistency  
- Same model architecture
- Same training algorithm

### **Outputs:**
```
src/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best_model.pth
â”‚   â””â”€â”€ checkpoint_epoch_*.pth
â”œâ”€â”€ samples/
â”‚   â””â”€â”€ epoch_*/
â””â”€â”€ logs/
```

---

ğŸ”¥ **Káº¿t quáº£ cuá»‘i cÃ¹ng**: CycleGAN training tá»« **94 giá»** xuá»‘ng **15 phÃºt**! 