# Dá»± Ã¡n Chuyá»ƒn Ä‘á»•i MRI thÃ nh CT mÃ´ phá»ng sá»­ dá»¥ng CycleGAN - TÃ i liá»‡u Chi tiáº¿t

## ğŸ“‹ Tá»•ng quan

Dá»± Ã¡n nÃ y triá»ƒn khai mÃ´ hÃ¬nh **CycleGAN** Ä‘á»ƒ chuyá»ƒn Ä‘á»•i áº£nh MRI thÃ nh áº£nh CT mÃ´ phá»ng phá»¥c vá»¥ cho **láº­p káº¿ hoáº¡ch xáº¡ trá»‹** trong y há»c. MÃ´ hÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc CycleGAN vá»›i PatchGAN discriminator vÃ  tÃ­ch há»£p nhiá»u loss function tiÃªn tiáº¿n bao gá»“m perceptual loss, adversarial loss, cycle consistency loss vÃ  identity loss.

### ğŸ¯ Má»¥c tiÃªu dá»± Ã¡n
- **Váº¥n Ä‘á» giáº£i quyáº¿t**: Táº¡o ra áº£nh CT mÃ´ phá»ng tá»« áº£nh MRI Ä‘á»ƒ há»— trá»£ láº­p káº¿ hoáº¡ch xáº¡ trá»‹ khi khÃ´ng cÃ³ sáºµn áº£nh CT
- **Ã nghÄ©a y há»c**: Giáº£m liá»u phÃ³ng xáº¡ cho bá»‡nh nhÃ¢n, tiáº¿t kiá»‡m chi phÃ­ vÃ  thá»i gian
- **ThÃ¡ch thá»©c ká»¹ thuáº­t**: Äáº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c cao cá»§a áº£nh CT mÃ´ phá»ng Ä‘á»ƒ phá»¥c vá»¥ má»¥c Ä‘Ã­ch y táº¿

## ğŸ—ï¸ Cáº¥u trÃºc dá»± Ã¡n

```
mri-to-ct/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ MRI/                 # Dá»¯ liá»‡u MRI training (brain_001.nii.gz - brain_046.nii.gz)
â”‚   â”œâ”€â”€ CT/                  # Dá»¯ liá»‡u CT training (brain_001.nii.gz - brain_046.nii.gz)
â”‚   â””â”€â”€ Test/
â”‚       â”œâ”€â”€ MRI/            # Dá»¯ liá»‡u MRI test
â”‚       â””â”€â”€ CT/             # Dá»¯ liá»‡u CT test
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py      # Táº£i vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ models.py           # Kiáº¿n trÃºc CycleGAN vÃ  cÃ¡c mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ train.py            # Script training
â”‚   â”œâ”€â”€ test.py             # Script testing vÃ  Ä‘Ã¡nh giÃ¡
â”‚   â”œâ”€â”€ metrics.py          # CÃ¡c metrics Ä‘Ã¡nh giÃ¡ (MAE, MSE, SSIM, PSNR)
â”‚   â””â”€â”€ utils.py            # CÃ¡c hÃ m tiá»‡n Ã­ch
â”œâ”€â”€ requirements.txt        # CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
â””â”€â”€ README.md
```

## ğŸ”¬ Chi tiáº¿t Tiá»n xá»­ lÃ½ Dá»¯ liá»‡u

### 1. N4 Bias Field Correction

**Má»¥c Ä‘Ã­ch**: Hiá»‡u chá»‰nh Ä‘á»™ lá»‡ch tá»« trÆ°á»ng trong áº£nh MRI

**LÃ½ do sá»­ dá»¥ng**:
- áº¢nh MRI thÆ°á»ng bá»‹ nhiá»…u do sá»± khÃ´ng Ä‘á»“ng nháº¥t cá»§a tá»« trÆ°á»ng
- Bias field gÃ¢y ra Ä‘á»™ sÃ¡ng khÃ´ng Ä‘á»u trÃªn toÃ n bá»™ áº£nh
- áº¢nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng training vÃ  káº¿t quáº£ cuá»‘i cÃ¹ng

**Tham sá»‘ Ä‘Æ°á»£c sá»­ dá»¥ng**:
```python
corrector = sitk.N4BiasFieldCorrectionImageFilter()
corrector.SetMaximumNumberOfIterations([50] * 4)
```
- **50 iterations Ã— 4 levels**: Äáº£m báº£o hiá»‡u chá»‰nh chÃ­nh xÃ¡c qua nhiá»u level resolution
- **4 levels**: Multi-resolution approach giÃºp xá»­ lÃ½ bias field á»Ÿ nhiá»u táº§n sá»‘ khÃ¡c nhau

**TÃ¡c Ä‘á»™ng**: Cáº£i thiá»‡n contrast vÃ  Ä‘á»“ng nháº¥t intensity, táº¡o Ä‘iá»u kiá»‡n tá»‘t cho cÃ¡c bÆ°á»›c xá»­ lÃ½ tiáº¿p theo

### 2. Binary Masking vá»›i Otsu Thresholding

**Má»¥c Ä‘Ã­ch**: Táº¡o mask Ä‘á»ƒ phÃ¢n tÃ¡ch vÃ¹ng nÃ£o khá»i background

**LÃ½ do sá»­ dá»¥ng**:
- Loáº¡i bá» noise vÃ  artifacts á»Ÿ vÃ¹ng background
- Táº­p trung training vÃ o vÃ¹ng quan trá»ng (mÃ´ nÃ£o)
- Giáº£m thiá»ƒu áº£nh hÆ°á»Ÿng cá»§a vÃ¹ng khÃ´ng chá»©a thÃ´ng tin y há»c

**Quy trÃ¬nh xá»­ lÃ½**:
```python
# Chuáº©n hÃ³a vá» [0, 255]
normalized = ((image_array - image_array.min()) / 
             (image_array.max() - image_array.min()) * 255).astype(np.uint8)

# Otsu thresholding
threshold = filters.threshold_otsu(normalized)
binary_mask = normalized > threshold

# Post-processing
binary_mask = morphology.remove_small_objects(binary_mask, min_size=1000)
binary_mask = ndimage.binary_fill_holes(binary_mask)
```

**Tham sá»‘ chi tiáº¿t**:
- **min_size=1000**: Loáº¡i bá» cÃ¡c object nhá» hÆ¡n 1000 pixels, giá»¯ láº¡i chá»‰ cÃ¡c vÃ¹ng mÃ´ nÃ£o chÃ­nh
- **binary_fill_holes**: Láº¥p Ä‘áº§y cÃ¡c lá»— há»•ng nhá» trong mask, táº¡o vÃ¹ng liÃªn tá»¥c

**Hiá»‡u quáº£**: Cáº£i thiá»‡n SNR (Signal-to-Noise Ratio) vÃ  giáº£m computational cost

### 3. Intensity Normalization

**Má»¥c Ä‘Ã­ch**: Chuáº©n hÃ³a giÃ¡ trá»‹ pixel Ä‘á»ƒ á»•n Ä‘á»‹nh training

**PhÆ°Æ¡ng phÃ¡p Min-Max normalization**:
```python
masked_values = image_array[mask > 0]
min_val = np.min(masked_values)
max_val = np.max(masked_values)
if max_val > min_val:
    # Min-Max normalization vá» [0, 1]
    image_array = (image_array - min_val) / (max_val - min_val)

# Ãp dá»¥ng mask
image_array = image_array * mask

# Chuyá»ƒn vá» [-1, 1] Ä‘á»ƒ phÃ¹ há»£p vá»›i Tanh activation
image_array = image_array * 2.0 - 1.0
```

**LÃ½ do chá»n Min-Max**:
- **Full dynamic range utilization**: Sá»­ dá»¥ng toÃ n bá»™ range [0,1] sau khi Ä‘Ã£ loáº¡i bá» outliers báº±ng mask
- **Intuitive interpretation**: 0 = pixel tá»‘i nháº¥t trong brain, 1 = pixel sÃ¡ng nháº¥t trong brain
- **Optimal for generation**: PhÃ¹ há»£p vá»›i generative models khi Ä‘Ã£ cÃ³ binary mask loáº¡i bá» background
- **Cross-subject consistency**: CÃ¹ng tissue type sáº½ cÃ³ similar relative position trong [0,1] range

**Chuyá»ƒn Ä‘á»•i [-1, 1]**:
- PhÃ¹ há»£p vá»›i Tanh activation cá»§a Generator output
- Standard practice trong CycleGAN vÃ  cÃ¡c generative models
- Äáº£m báº£o symmetric range around zero

### 4. Data Augmentation

**Má»¥c Ä‘Ã­ch**: TÄƒng cÆ°á»ng dá»¯ liá»‡u Ä‘á»ƒ trÃ¡nh overfitting

**CÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c sá»­ dá»¥ng**:

#### 4.1 Geometric Transformations
```python
# Random rotation (-10Â° Ä‘áº¿n +10Â°)
if random.random() > 0.5:
    angle = random.uniform(-10, 10)
    mri_slice = ndimage.rotate(mri_slice, angle, reshape=False, mode='nearest')
```
- **GÃ³c xoay [-10Â°, +10Â°]**: MÃ´ phá»ng sá»± thay Ä‘á»•i tÆ° tháº¿ Ä‘áº§u tá»± nhiÃªn
- **reshape=False**: Giá»¯ nguyÃªn kÃ­ch thÆ°á»›c áº£nh
- **mode='nearest'**: TrÃ¡nh interpolation artifacts

#### 4.2 Flip Operations
```python
# Horizontal vÃ  Vertical flip vá»›i xÃ¡c suáº¥t 50%
if random.random() > 0.5:
    mri_slice = np.fliplr(mri_slice)  # Left-Right flip
if random.random() > 0.5:
    mri_slice = np.flipud(mri_slice)  # Up-Down flip
```
- **XÃ¡c suáº¥t 50%**: CÃ¢n báº±ng giá»¯a dá»¯ liá»‡u gá»‘c vÃ  augmented
- **Anatomical consideration**: Pháº£n Ã¡nh tÃ­nh Ä‘á»‘i xá»©ng tá»± nhiÃªn cá»§a nÃ£o

#### 4.3 Intensity Scaling
```python
# Random intensity scaling (Â±10%)
if random.random() > 0.5:
    scale_factor = random.uniform(0.9, 1.1)
    mri_slice = mri_slice * scale_factor
```
- **Scaling range [0.9, 1.1]**: MÃ´ phá»ng sá»± biáº¿n Ä‘á»•i contrast tá»± nhiÃªn
- **Chá»‰ Ã¡p dá»¥ng cho MRI**: CT cÃ³ range cá»‘ Ä‘á»‹nh nÃªn khÃ´ng nÃªn thay Ä‘á»•i

**TÃ¡c Ä‘á»™ng tá»•ng thá»ƒ**: TÄƒng gáº¥p 8 láº§n sá»‘ lÆ°á»£ng dá»¯ liá»‡u hiá»‡u quáº£, cáº£i thiá»‡n kháº£ nÄƒng generalization

## ğŸ§  Kiáº¿n trÃºc MÃ´ hÃ¬nh Chi tiáº¿t

### Generator Architecture

**Thiáº¿t káº¿ Encoder-Decoder vá»›i Residual Blocks**:

```python
# Encoder (downsampling)
- ReflectionPad2d(3) + Conv2d(1â†’64, kernel=7) + InstanceNorm2d + ReLU
- Conv2d(64â†’128, kernel=3, stride=2) + InstanceNorm2d + ReLU  # 1/2 resolution
- Conv2d(128â†’256, kernel=3, stride=2) + InstanceNorm2d + ReLU # 1/4 resolution

# Residual Blocks (9 blocks)
- 9 Ã— ResidualBlock(256 features)

# Decoder (upsampling)  
- ConvTranspose2d(256â†’128, kernel=3, stride=2) + InstanceNorm2d + ReLU # 1/2 resolution
- ConvTranspose2d(128â†’64, kernel=3, stride=2) + InstanceNorm2d + ReLU  # full resolution
- ReflectionPad2d(3) + Conv2d(64â†’1, kernel=7) + Tanh
```

**LÃ½ do thiáº¿t káº¿**:
- **9 Residual Blocks**: Äá»§ sÃ¢u Ä‘á»ƒ há»c complex mappings, trÃ¡nh vanishing gradient
- **ReflectionPad**: Giáº£m artifacts á»Ÿ biÃªn áº£nh so vá»›i zero padding
- **InstanceNorm**: PhÃ¹ há»£p vá»›i style transfer, tá»‘t hÆ¡n BatchNorm cho medical images
- **Tanh activation**: Output trong [-1, 1], phÃ¹ há»£p vá»›i normalized input

### PatchGAN Discriminator

**Thiáº¿t káº¿ 70Ã—70 PatchGAN**:
```python
# Layer 1: Conv2d(1â†’64, kernel=4, stride=2) + LeakyReLU(0.2)     # No normalization
# Layer 2: Conv2d(64â†’128, kernel=4, stride=2) + InstanceNorm + LeakyReLU(0.2)
# Layer 3: Conv2d(128â†’256, kernel=4, stride=2) + InstanceNorm + LeakyReLU(0.2)  
# Layer 4: Conv2d(256â†’512, kernel=4, stride=1) + InstanceNorm + LeakyReLU(0.2)
# Output:  Conv2d(512â†’1, kernel=4, stride=1)                     # No activation
```

**Æ¯u Ä‘iá»ƒm PatchGAN**:
- **Local discrimination**: ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng á»Ÿ má»©c local patches (70Ã—70)
- **Fewer parameters**: Hiá»‡u quáº£ hÆ¡n full-image discriminator
- **Better texture quality**: Táº­p trung vÃ o chi tiáº¿t texture thay vÃ¬ global structure

## ğŸ“Š Chi tiáº¿t Loss Functions vÃ  Trá»ng sá»‘

### 1. Adversarial Loss (Î» = 1.0)

**CÃ´ng thá»©c**:
```python
loss_gan_ct = F.mse_loss(D_CT(fake_ct), torch.ones_like(D_CT(fake_ct)))
loss_gan_mri = F.mse_loss(D_MRI(fake_mri), torch.ones_like(D_MRI(fake_mri)))
loss_gan = (loss_gan_ct + loss_gan_mri) * 0.5
```

**LÃ½ do chá»n MSE thay vÃ¬ BCE**:
- **Least-squares GAN**: á»”n Ä‘á»‹nh training hÆ¡n, Ã­t bá»‹ mode collapse
- **Smoother gradients**: Gradient penalty tá»± nhiÃªn gáº§n decision boundary
- **Better convergence**: PhÃ¹ há»£p vá»›i medical image domain

**Trá»ng sá»‘ Î»_adversarial = 1.0**:
- **Baseline weight**: LÃ m reference cho cÃ¡c loss khÃ¡c
- **Balanced contribution**: KhÃ´ng quÃ¡ dominant so vá»›i cycle consistency

### 2. Cycle Consistency Loss (Î» = 10.0)

**CÃ´ng thá»©c**:
```python
loss_cycle_mri = F.l1_loss(G_CT2MRI(G_MRI2CT(mri)), mri)
loss_cycle_ct = F.l1_loss(G_MRI2CT(G_CT2MRI(ct)), ct)
loss_cycle = (loss_cycle_mri + loss_cycle_ct) * 0.5
```

**LÃ½ do trá»ng sá»‘ cao (Î» = 10.0)**:
- **Core constraint**: Äáº£m báº£o tÃ­nh consistency cÆ¡ báº£n cá»§a cycle
- **Prevent mode collapse**: NgÄƒn generator táº¡o ra mapping tÃ¹y Ã½
- **Medical accuracy**: Äáº·c biá»‡t quan trá»ng trong á»©ng dá»¥ng y táº¿
- **Empirical validation**: GiÃ¡ trá»‹ 10.0 Ä‘Æ°á»£c verify qua nhiá»u nghiÃªn cá»©u CycleGAN

**L1 vs L2 loss**:
- **L1 Loss**: Ãt bá»‹ blur hÆ¡n, preserve sharp edges tá»‘t hÆ¡n
- **Robust to outliers**: Quan trá»ng vá»›i medical images cÃ³ noise

### 3. Identity Loss (Î» = 5.0)

**CÃ´ng thá»©c**:
```python
loss_identity_ct = F.l1_loss(G_MRI2CT(ct), ct)
loss_identity_mri = F.l1_loss(G_CT2MRI(mri), mri)
loss_identity = (loss_identity_ct + loss_identity_mri) * 0.5
```

**Má»¥c Ä‘Ã­ch**:
- **Color preservation**: Giá»¯ nguyÃªn tÃ´ng mÃ u khi input Ä‘Ã£ Ä‘Ãºng domain
- **Reduce overshoot**: TrÃ¡nh generator thay Ä‘á»•i quÃ¡ má»©c khÃ´ng cáº§n thiáº¿t

**Trá»ng sá»‘ Î»_identity = 5.0**:
- **Moderate constraint**: KhÃ´ng quÃ¡ restrictive nhÆ° cycle consistency
- **Medical consideration**: Äáº£m báº£o intensity values Ä‘Æ°á»£c preserve phÃ¹ há»£p
- **Half of cycle weight**: CÃ¢n báº±ng giá»¯a consistency vÃ  flexibility

### 4. Perceptual Loss (Î» = 1.0)

**Kiáº¿n trÃºc VGG19-based**:
```python
feature_layers = [3, 8, 15, 22]  # ReLU1_2, ReLU2_2, ReLU3_4, ReLU4_4
loss_perceptual = Î£ MSE(VGG_i(fake_ct), VGG_i(real_ct))
```

**LÃ½ do chá»n VGG19**:
- **Pre-trained features**: ÄÃ£ há»c Ä‘Æ°á»£c generic visual patterns
- **Multi-scale representation**: Tá»« low-level Ä‘áº¿n high-level features
- **Medical imaging validation**: Hiá»‡u quáº£ Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh vá»›i medical images

**Feature layers selection**:
- **Layer 3 (ReLU1_2)**: Low-level textures, edges
- **Layer 8 (ReLU2_2)**: Medium-level patterns  
- **Layer 15 (ReLU3_4)**: High-level features
- **Layer 22 (ReLU4_4)**: Semantic representations

**Trá»ng sá»‘ Î»_perceptual = 1.0**:
- **Complementary role**: Bá»• sung cho pixel-wise losses
- **Equal importance**: Vá»›i adversarial loss Ä‘á»ƒ cÃ¢n báº±ng quality
- **Medical relevance**: Äáº£m báº£o similarity á»Ÿ multiple perception levels

### 5. Tá»•ng há»£p Loss Function

**Total Generator Loss**:
```python
L_total = Î»_adversarial Ã— L_GAN + 
          Î»_cycle Ã— L_cycle + 
          Î»_identity Ã— L_identity + 
          Î»_perceptual Ã— L_perceptual

L_total = 1.0 Ã— L_GAN + 10.0 Ã— L_cycle + 5.0 Ã— L_identity + 1.0 Ã— L_perceptual
```

**Hierarchy cá»§a trá»ng sá»‘**:
1. **L_cycle (10.0)**: Highest priority - Ä‘áº£m báº£o consistency cÆ¡ báº£n
2. **L_identity (5.0)**: Medium priority - preserve original characteristics  
3. **L_GAN (1.0)**: Standard priority - realistic generation
4. **L_perceptual (1.0)**: Standard priority - perceptual quality

**TÃ¡c Ä‘á»™ng cá»§a tá»«ng thÃ nh pháº§n**:
- **Cycle consistency**: Äáº£m báº£o mapping cÃ³ thá»ƒ Ä‘áº£o ngÆ°á»£c
- **Identity loss**: Giá»¯ nguyÃªn khi khÃ´ng cáº§n transform
- **Adversarial loss**: Táº¡o ra áº£nh realistic
- **Perceptual loss**: Cáº£i thiá»‡n cháº¥t lÆ°á»£ng visual vÃ  texture

## ğŸ“ˆ Metrics ÄÃ¡nh giÃ¡

### 1. Mean Absolute Error (MAE)
- **CÃ´ng thá»©c**: `MAE = (1/N) Î£ |y_pred - y_true|`
- **Ã nghÄ©a**: Sai sá»‘ trung bÃ¬nh tuyá»‡t Ä‘á»‘i, Ä‘Æ¡n vá»‹ giá»‘ng pixel intensity
- **Táº§m quan trá»ng**: Äo lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c pixel-level

### 2. Mean Squared Error (MSE)  
- **CÃ´ng thá»©c**: `MSE = (1/N) Î£ (y_pred - y_true)Â²`
- **Ã nghÄ©a**: Nháº¥n máº¡nh cÃ¡c sai sá»‘ lá»›n, penalty cho outliers
- **Sá»­ dá»¥ng**: ÄÃ¡nh giÃ¡ overall reconstruction quality

### 3. Peak Signal-to-Noise Ratio (PSNR)
- **CÃ´ng thá»©c**: `PSNR = 20 Ã— logâ‚â‚€(MAX_I / âˆšMSE)`
- **ÄÆ¡n vá»‹**: Decibel (dB)
- **GiÃ¡ trá»‹ tá»‘t**: >25 dB cho medical images
- **Ã nghÄ©a**: Tá»· lá»‡ signal/noise, cao hÆ¡n = cháº¥t lÆ°á»£ng tá»‘t hÆ¡n

### 4. Structural Similarity Index (SSIM)
- **Range**: [0, 1], cÃ ng gáº§n 1 cÃ ng tá»‘t
- **ThÃ nh pháº§n**: Luminance Ã— Contrast Ã— Structure
- **Æ¯u Ä‘iá»ƒm**: TÆ°Æ¡ng quan tá»‘t vá»›i perception cá»§a con ngÆ°á»i
- **Medical relevance**: Quan trá»ng cho texture vÃ  structural details

### 5. Normalized Cross Correlation (NCC)
- **Range**: [-1, 1], lÃ½ tÆ°á»Ÿng lÃ  1
- **Ã nghÄ©a**: Äo correlation giá»¯a hai áº£nh
- **Robust**: KhÃ´ng bá»‹ áº£nh hÆ°á»Ÿng bá»Ÿi linear intensity changes

## ğŸš€ HÆ°á»›ng dáº«n Sá»­ dá»¥ng

### CÃ i Ä‘áº·t Dependencies

```bash
git clone <repository-url>
cd mri-to-ct
pip install -r requirements.txt
```

### Training

```bash
cd src
python train.py
```

**Tham sá»‘ Training cÃ³ thá»ƒ Ä‘iá»u chá»‰nh**:
```python
config = {
    'batch_size': 4,          # TÃ¹y thuá»™c GPU memory
    'num_epochs': 200,        # Äá»§ Ä‘á»ƒ converge
    'lr_G': 0.0002,          # Learning rate cho Generator
    'lr_D': 0.0002,          # Learning rate cho Discriminator  
    'decay_epoch': 100,       # Báº¯t Ä‘áº§u decay LR
    'decay_epochs': 100       # Sá»‘ epoch Ä‘á»ƒ decay vá» 0
}
```

### Testing

#### Test má»™t áº£nh MRI Ä‘Æ¡n láº»:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode single \
               --mri_path data/MRI/brain_001.nii.gz \
               --output_dir results/
```

#### Test vá»›i ground truth Ä‘á»ƒ tÃ­nh metrics:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode with_gt \
               --mri_path data/MRI/brain_001.nii.gz \
               --ct_path data/CT/brain_001.nii.gz \
               --output_dir results/
```

#### Test trÃªn toÃ n bá»™ dataset:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode dataset \
               --mri_dir data/Test/MRI \
               --ct_dir data/Test/CT \
               --output_dir results/
```

## ğŸ“ Dá»¯ liá»‡u Input/Output

### Dá»¯ liá»‡u Ä‘áº§u vÃ o
- **Format**: NIfTI (.nii.gz)
- **Naming convention**: brain_001.nii.gz Ä‘áº¿n brain_046.nii.gz
- **Pairing**: Má»—i file MRI cÃ³ file CT tÆ°Æ¡ng á»©ng cÃ¹ng tÃªn
- **Preprocessing**: Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c cáº¯t vÃ¹ng (cropped) thá»§ cÃ´ng
- **Resolution**: Tá»± Ä‘á»™ng resize vá» 256Ã—256 cho training

### Káº¿t quáº£ Ä‘áº§u ra
- **Synthetic CT**: File .nii.gz vá»›i suffix "_synthetic_ct"
- **Comparison images**: File .png hiá»ƒn thá»‹ MRI input, CT mÃ´ phá»ng, vÃ  difference map
- **Metrics report**: CÃ¡c chá»‰ sá»‘ MAE, MSE, SSIM, PSNR, NCC
- **Tensorboard logs**: Theo dÃµi loss vÃ  metrics qua epochs

## âš™ï¸ YÃªu cáº§u Há»‡ thá»‘ng

### Hardware Requirements
- **GPU**: CUDA-enabled GPU vá»›i Ã­t nháº¥t 8GB VRAM (khuyáº¿n nghá»‹ 16GB+)
- **RAM**: Tá»‘i thiá»ƒu 16GB, khuyáº¿n nghá»‹ 32GB
- **Storage**: ~20GB cho dá»¯ liá»‡u, checkpoints vÃ  logs
- **CPU**: Multi-core processor Ä‘á»ƒ data loading

### Software Requirements
- **Python**: 3.7+
- **PyTorch**: 1.9.0+
- **CUDA**: 11.0+ (náº¿u sá»­ dá»¥ng GPU)
- **Operating System**: Linux (khuyáº¿n nghá»‹), Windows, macOS

## ğŸ“Š Monitoring vÃ  Debugging

### Tensorboard Monitoring
```bash
tensorboard --logdir logs/
```

**Metrics Ä‘Æ°á»£c track**:
- Training/Validation losses (G_total, G_gan, G_cycle, G_identity, G_perceptual)
- Discriminator losses (D_CT, D_MRI)
- Image quality metrics (MAE, MSE, SSIM, PSNR)
- Learning rates

### Sample Images
- **Frequency**: Má»—i 5 epochs
- **Location**: `samples/epoch_X/`
- **Content**: Real MRI, Fake CT, Real CT, Reconstructed images

### Checkpoint Strategy
- **Regular saves**: Má»—i 10 epochs
- **Best model**: Dá»±a trÃªn validation SSIM
- **Resume capability**: CÃ³ thá»ƒ tiáº¿p tá»¥c training tá»« checkpoint

## ğŸ”¬ Káº¿t quáº£ Mong Ä‘á»£i

### Performance Benchmarks
- **SSIM**: >0.85 cho high-quality synthesis
- **PSNR**: >25 dB
- **MAE**: <0.1 (vá»›i normalized intensity)
- **Training time**: 24-48 giá» trÃªn GPU RTX 3080

### Qualitative Assessment
- **Bone structures**: RÃµ nÃ©t vÃ  chÃ­nh xÃ¡c trong CT mÃ´ phá»ng
- **Soft tissue contrast**: TÆ°Æ¡ng Ä‘á»“ng vá»›i CT tháº­t
- **Artifacts**: Tá»‘i thiá»ƒu noise vÃ  distortion
- **Anatomical consistency**: Giá»¯ nguyÃªn cáº¥u trÃºc tá»« MRI

## âš ï¸ LÆ°u Ã½ Quan trá»ng

### Medical Applications
1. **Validation requirement**: Káº¿t quáº£ cáº§n Ä‘Æ°á»£c xÃ¡c thá»±c bá»Ÿi chuyÃªn gia y táº¿
2. **Clinical responsibility**: KhÃ´ng sá»­ dá»¥ng trá»±c tiáº¿p mÃ  khÃ´ng cÃ³ supervision
3. **Regulatory compliance**: TuÃ¢n thá»§ cÃ¡c quy Ä‘á»‹nh y táº¿ Ä‘á»‹a phÆ°Æ¡ng
4. **Quality assurance**: Kiá»ƒm tra ká»¹ lÆ°á»¡ng trÆ°á»›c khi sá»­ dá»¥ng lÃ¢m sÃ ng

### Technical Considerations
1. **Data quality**: Cháº¥t lÆ°á»£ng input áº£nh hÆ°á»Ÿng trá»±c tiáº¿p Ä‘áº¿n output
2. **Domain specificity**: Model Ä‘Æ°á»£c train cho brain images
3. **Generalization**: Cáº§n validation vá»›i different scanners/protocols
4. **Computational cost**: Training resource-intensive

### Hyperparameter Tuning
- **Learning rates**: CÃ³ thá»ƒ cáº§n Ä‘iá»u chá»‰nh tÃ¹y dataset
- **Loss weights**: Fine-tune dá»±a trÃªn validation metrics
- **Architecture**: CÃ³ thá»ƒ thay Ä‘á»•i sá»‘ residual blocks
- **Training schedule**: Äiá»u chá»‰nh decay timing

## ğŸ“š TÃ i liá»‡u Tham kháº£o

### Core Papers
- **CycleGAN**: Zhu, J.Y., et al. "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks." ICCV 2017
- **Perceptual Loss**: Johnson, J., et al. "Perceptual Losses for Real-Time Style Transfer and Super-Resolution." ECCV 2016
- **PatchGAN**: Isola, P., et al. "Image-to-Image Translation with Conditional Adversarial Networks." CVPR 2017

### Medical Imaging References
- **MRI-CT Synthesis**: Lei, Y., et al. "MRI-only based synthetic CT generation using dense cycle consistent generative adversarial networks." Medical Physics 2019
- **N4 Bias Correction**: Tustison, N.J., et al. "N4ITK: improved N3 bias correction." IEEE TMI 2010

### Implementation Guides
- **README Best Practices**: [How to Write a Good README](https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/)
- **Documentation Standards**: [Make a README](https://www.makeareadme.com/)

## ğŸ¤ Contributing

### Development Guidelines
1. **Code style**: Follow PEP 8 conventions
2. **Documentation**: Comment all functions vÃ  classes
3. **Testing**: Add unit tests for new features
4. **Version control**: Use descriptive commit messages

### Bug Reports
- Include system specifications
- Provide error logs vÃ  stack traces
- Describe reproduction steps
- Attach sample data if possible

## ğŸ“„ License

[ThÃªm thÃ´ng tin license phÃ¹ há»£p]

## ğŸ‘¥ LiÃªn há»‡

**NhÃ³m phÃ¡t triá»ƒn**: MRI-to-CT Research Team
**Email**: [ThÃªm email liÃªn há»‡]
**Institution**: [ThÃªm thÃ´ng tin tá»• chá»©c]

---

**LÆ°u Ã½**: ÄÃ¢y lÃ  dá»± Ã¡n nghiÃªn cá»©u. Káº¿t quáº£ cáº§n Ä‘Æ°á»£c validation vÃ  approval tá»« chuyÃªn gia y táº¿ trÆ°á»›c khi sá»­ dá»¥ng trong thá»±c táº¿ lÃ¢m sÃ ng. 