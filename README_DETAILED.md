# D·ª± √°n Chuy·ªÉn ƒë·ªïi MRI th√†nh CT m√¥ ph·ªèng s·ª≠ d·ª•ng CycleGAN - T√†i li·ªáu Chi ti·∫øt

## üìã T·ªïng quan

D·ª± √°n n√†y tri·ªÉn khai m√¥ h√¨nh **CycleGAN** ƒë·ªÉ chuy·ªÉn ƒë·ªïi ·∫£nh MRI th√†nh ·∫£nh CT m√¥ ph·ªèng ph·ª•c v·ª• cho **l·∫≠p k·∫ø ho·∫°ch x·∫° tr·ªã** trong y h·ªçc. M√¥ h√¨nh s·ª≠ d·ª•ng ki·∫øn tr√∫c CycleGAN v·ªõi PatchGAN discriminator v√† t√≠ch h·ª£p nhi·ªÅu loss function ti√™n ti·∫øn bao g·ªìm perceptual loss, adversarial loss, cycle consistency loss v√† identity loss.

### üéØ M·ª•c ti√™u d·ª± √°n
- **V·∫•n ƒë·ªÅ gi·∫£i quy·∫øt**: T·∫°o ra ·∫£nh CT m√¥ ph·ªèng t·ª´ ·∫£nh MRI ƒë·ªÉ h·ªó tr·ª£ l·∫≠p k·∫ø ho·∫°ch x·∫° tr·ªã khi kh√¥ng c√≥ s·∫µn ·∫£nh CT
- **√ù nghƒ©a y h·ªçc**: Gi·∫£m li·ªÅu ph√≥ng x·∫° cho b·ªánh nh√¢n, ti·∫øt ki·ªám chi ph√≠ v√† th·ªùi gian
- **Th√°ch th·ª©c k·ªπ thu·∫≠t**: ƒê·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c cao c·ªßa ·∫£nh CT m√¥ ph·ªèng ƒë·ªÉ ph·ª•c v·ª• m·ª•c ƒë√≠ch y t·∫ø

## üèóÔ∏è C·∫•u tr√∫c d·ª± √°n

```
mri-to-ct/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ MRI/                 # D·ªØ li·ªáu MRI training (brain_001.nii.gz - brain_046.nii.gz)
‚îÇ   ‚îú‚îÄ‚îÄ CT/                  # D·ªØ li·ªáu CT training (brain_001.nii.gz - brain_046.nii.gz)
‚îÇ   ‚îî‚îÄ‚îÄ Test/
‚îÇ       ‚îú‚îÄ‚îÄ MRI/            # D·ªØ li·ªáu MRI test
‚îÇ       ‚îî‚îÄ‚îÄ CT/             # D·ªØ li·ªáu CT test
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py      # T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
‚îÇ   ‚îú‚îÄ‚îÄ models.py           # Ki·∫øn tr√∫c CycleGAN v√† c√°c m√¥ h√¨nh
‚îÇ   ‚îú‚îÄ‚îÄ train.py            # Script training
‚îÇ   ‚îú‚îÄ‚îÄ test.py             # Script testing v√† ƒë√°nh gi√°
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py          # C√°c metrics ƒë√°nh gi√° (MAE, MSE, SSIM, PSNR)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py            # C√°c h√†m ti·ªán √≠ch
‚îú‚îÄ‚îÄ requirements.txt        # C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
‚îî‚îÄ‚îÄ README.md
```

## üî¨ Chi ti·∫øt Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu

### 1. N4 Bias Field Correction

**M·ª•c ƒë√≠ch**: Hi·ªáu ch·ªânh ƒë·ªô l·ªách t·ª´ tr∆∞·ªùng trong ·∫£nh MRI

**L√Ω do s·ª≠ d·ª•ng**:
- ·∫¢nh MRI th∆∞·ªùng b·ªã nhi·ªÖu do s·ª± kh√¥ng ƒë·ªìng nh·∫•t c·ªßa t·ª´ tr∆∞·ªùng
- Bias field g√¢y ra ƒë·ªô s√°ng kh√¥ng ƒë·ªÅu tr√™n to√†n b·ªô ·∫£nh
- ·∫¢nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng training v√† k·∫øt qu·∫£ cu·ªëi c√πng

**Tham s·ªë ƒë∆∞·ª£c s·ª≠ d·ª•ng**:
```python
corrector = sitk.N4BiasFieldCorrectionImageFilter()
corrector.SetMaximumNumberOfIterations([50] * 4)
```
- **50 iterations √ó 4 levels**: ƒê·∫£m b·∫£o hi·ªáu ch·ªânh ch√≠nh x√°c qua nhi·ªÅu level resolution
- **4 levels**: Multi-resolution approach gi√∫p x·ª≠ l√Ω bias field ·ªü nhi·ªÅu t·∫ßn s·ªë kh√°c nhau

**T√°c ƒë·ªông**: C·∫£i thi·ªán contrast v√† ƒë·ªìng nh·∫•t intensity, t·∫°o ƒëi·ªÅu ki·ªán t·ªët cho c√°c b∆∞·ªõc x·ª≠ l√Ω ti·∫øp theo

### 2. Binary Masking v·ªõi Otsu Thresholding

**M·ª•c ƒë√≠ch**: T·∫°o mask ƒë·ªÉ ph√¢n t√°ch v√πng n√£o kh·ªèi background

**L√Ω do s·ª≠ d·ª•ng**:
- Lo·∫°i b·ªè noise v√† artifacts ·ªü v√πng background
- T·∫≠p trung training v√†o v√πng quan tr·ªçng (m√¥ n√£o)
- Gi·∫£m thi·ªÉu ·∫£nh h∆∞·ªüng c·ªßa v√πng kh√¥ng ch·ª©a th√¥ng tin y h·ªçc

**Quy tr√¨nh x·ª≠ l√Ω**:
```python
# Chu·∫©n h√≥a v·ªÅ [0, 255]
normalized = ((image_array - image_array.min()) / 
             (image_array.max() - image_array.min()) * 255).astype(np.uint8)

# Otsu thresholding
threshold = filters.threshold_otsu(normalized)
binary_mask = normalized > threshold

# Post-processing
binary_mask = morphology.remove_small_objects(binary_mask, min_size=1000)
binary_mask = ndimage.binary_fill_holes(binary_mask)
```

**Tham s·ªë chi ti·∫øt**:
- **min_size=1000**: Lo·∫°i b·ªè c√°c object nh·ªè h∆°n 1000 pixels, gi·ªØ l·∫°i ch·ªâ c√°c v√πng m√¥ n√£o ch√≠nh
- **binary_fill_holes**: L·∫•p ƒë·∫ßy c√°c l·ªó h·ªïng nh·ªè trong mask, t·∫°o v√πng li√™n t·ª•c

**Hi·ªáu qu·∫£**: C·∫£i thi·ªán SNR (Signal-to-Noise Ratio) v√† gi·∫£m computational cost

### 3. Intensity Normalization

**M·ª•c ƒë√≠ch**: Chu·∫©n h√≥a gi√° tr·ªã pixel ƒë·ªÉ ·ªïn ƒë·ªãnh training

**Ph∆∞∆°ng ph√°p Min-Max normalization**:
```python
masked_values = image_array[mask > 0]
min_val = np.min(masked_values)
max_val = np.max(masked_values)
if max_val > min_val:
    # Min-Max normalization v·ªÅ [0, 1]
    image_array = (image_array - min_val) / (max_val - min_val)

# √Åp d·ª•ng mask
image_array = image_array * mask

# Chuy·ªÉn v·ªÅ [-1, 1] ƒë·ªÉ ph√π h·ª£p v·ªõi Tanh activation
image_array = image_array * 2.0 - 1.0
```

**L√Ω do ch·ªçn Min-Max**:
- **Full dynamic range utilization**: S·ª≠ d·ª•ng to√†n b·ªô range [0,1] sau khi ƒë√£ lo·∫°i b·ªè outliers b·∫±ng mask
- **Intuitive interpretation**: 0 = pixel t·ªëi nh·∫•t trong brain, 1 = pixel s√°ng nh·∫•t trong brain
- **Optimal for generation**: Ph√π h·ª£p v·ªõi generative models khi ƒë√£ c√≥ binary mask lo·∫°i b·ªè background
- **Cross-subject consistency**: C√πng tissue type s·∫Ω c√≥ similar relative position trong [0,1] range

**Chuy·ªÉn ƒë·ªïi [-1, 1]**:
- Ph√π h·ª£p v·ªõi Tanh activation c·ªßa Generator output
- Standard practice trong CycleGAN v√† c√°c generative models
- ƒê·∫£m b·∫£o symmetric range around zero

### 4. Data Augmentation

**M·ª•c ƒë√≠ch**: TƒÉng c∆∞·ªùng d·ªØ li·ªáu ƒë·ªÉ tr√°nh overfitting

**C√°c k·ªπ thu·∫≠t ƒë∆∞·ª£c s·ª≠ d·ª•ng**:

#### 4.1 Geometric Transformations
```python
# Random rotation (-10¬∞ ƒë·∫øn +10¬∞)
if random.random() > 0.5:
    angle = random.uniform(-10, 10)
    mri_slice = ndimage.rotate(mri_slice, angle, reshape=False, mode='nearest')
```
- **G√≥c xoay [-10¬∞, +10¬∞]**: M√¥ ph·ªèng s·ª± thay ƒë·ªïi t∆∞ th·∫ø ƒë·∫ßu t·ª± nhi√™n
- **reshape=False**: Gi·ªØ nguy√™n k√≠ch th∆∞·ªõc ·∫£nh
- **mode='nearest'**: Tr√°nh interpolation artifacts

#### 4.2 Flip Operations
```python
# Horizontal v√† Vertical flip v·ªõi x√°c su·∫•t 50%
if random.random() > 0.5:
    mri_slice = np.fliplr(mri_slice)  # Left-Right flip
if random.random() > 0.5:
    mri_slice = np.flipud(mri_slice)  # Up-Down flip
```
- **X√°c su·∫•t 50%**: C√¢n b·∫±ng gi·ªØa d·ªØ li·ªáu g·ªëc v√† augmented
- **Anatomical consideration**: Ph·∫£n √°nh t√≠nh ƒë·ªëi x·ª©ng t·ª± nhi√™n c·ªßa n√£o

#### 4.3 Intensity Scaling
```python
# Random intensity scaling (¬±10%)
if random.random() > 0.5:
    scale_factor = random.uniform(0.9, 1.1)
    mri_slice = mri_slice * scale_factor
```
- **Scaling range [0.9, 1.1]**: M√¥ ph·ªèng s·ª± bi·∫øn ƒë·ªïi contrast t·ª± nhi√™n
- **Ch·ªâ √°p d·ª•ng cho MRI**: CT c√≥ range c·ªë ƒë·ªãnh n√™n kh√¥ng n√™n thay ƒë·ªïi

**T√°c ƒë·ªông t·ªïng th·ªÉ**: TƒÉng g·∫•p 8 l·∫ßn s·ªë l∆∞·ª£ng d·ªØ li·ªáu hi·ªáu qu·∫£, c·∫£i thi·ªán kh·∫£ nƒÉng generalization

## üß† Ki·∫øn tr√∫c M√¥ h√¨nh Chi ti·∫øt

### Generator Architecture

**Thi·∫øt k·∫ø Encoder-Decoder v·ªõi Residual Blocks**:

```python
# Encoder (downsampling)
- ReflectionPad2d(3) + Conv2d(1‚Üí64, kernel=7) + InstanceNorm2d + ReLU
- Conv2d(64‚Üí128, kernel=3, stride=2) + InstanceNorm2d + ReLU  # 1/2 resolution
- Conv2d(128‚Üí256, kernel=3, stride=2) + InstanceNorm2d + ReLU # 1/4 resolution

# Residual Blocks (9 blocks)
- 9 √ó ResidualBlock(256 features)

# Decoder (upsampling)  
- ConvTranspose2d(256‚Üí128, kernel=3, stride=2) + InstanceNorm2d + ReLU # 1/2 resolution
- ConvTranspose2d(128‚Üí64, kernel=3, stride=2) + InstanceNorm2d + ReLU  # full resolution
- ReflectionPad2d(3) + Conv2d(64‚Üí1, kernel=7) + Tanh
```

**L√Ω do thi·∫øt k·∫ø**:
- **9 Residual Blocks**: ƒê·ªß s√¢u ƒë·ªÉ h·ªçc complex mappings, tr√°nh vanishing gradient
- **ReflectionPad**: Gi·∫£m artifacts ·ªü bi√™n ·∫£nh so v·ªõi zero padding
- **InstanceNorm**: Ph√π h·ª£p v·ªõi style transfer, t·ªët h∆°n BatchNorm cho medical images
- **Tanh activation**: Output trong [-1, 1], ph√π h·ª£p v·ªõi normalized input

### PatchGAN Discriminator

**Thi·∫øt k·∫ø 70√ó70 PatchGAN**:
```python
# Layer 1: Conv2d(1‚Üí64, kernel=4, stride=2) + LeakyReLU(0.2)     # No normalization
# Layer 2: Conv2d(64‚Üí128, kernel=4, stride=2) + InstanceNorm + LeakyReLU(0.2)
# Layer 3: Conv2d(128‚Üí256, kernel=4, stride=2) + InstanceNorm + LeakyReLU(0.2)  
# Layer 4: Conv2d(256‚Üí512, kernel=4, stride=1) + InstanceNorm + LeakyReLU(0.2)
# Output:  Conv2d(512‚Üí1, kernel=4, stride=1)                     # No activation
```

**∆Øu ƒëi·ªÉm PatchGAN**:
- **Local discrimination**: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ·ªü m·ª©c local patches (70√ó70)
- **Fewer parameters**: Hi·ªáu qu·∫£ h∆°n full-image discriminator
- **Better texture quality**: T·∫≠p trung v√†o chi ti·∫øt texture thay v√¨ global structure

## üìä Chi ti·∫øt Loss Functions v√† Tr·ªçng s·ªë

### 1. Adversarial Loss (Œª = 1.0)

**C√¥ng th·ª©c**:
```python
loss_gan_ct = F.mse_loss(D_CT(fake_ct), torch.ones_like(D_CT(fake_ct)))
loss_gan_mri = F.mse_loss(D_MRI(fake_mri), torch.ones_like(D_MRI(fake_mri)))
loss_gan = (loss_gan_ct + loss_gan_mri) * 0.5
```

**L√Ω do ch·ªçn MSE thay v√¨ BCE**:
- **Least-squares GAN**: ·ªîn ƒë·ªãnh training h∆°n, √≠t b·ªã mode collapse
- **Smoother gradients**: Gradient penalty t·ª± nhi√™n g·∫ßn decision boundary
- **Better convergence**: Ph√π h·ª£p v·ªõi medical image domain

**Tr·ªçng s·ªë Œª_adversarial = 1.0**:
- **Baseline weight**: L√†m reference cho c√°c loss kh√°c
- **Balanced contribution**: Kh√¥ng qu√° dominant so v·ªõi cycle consistency

### 2. Cycle Consistency Loss (Œª = 10.0)

**C√¥ng th·ª©c**:
```python
loss_cycle_mri = F.l1_loss(G_CT2MRI(G_MRI2CT(mri)), mri)
loss_cycle_ct = F.l1_loss(G_MRI2CT(G_CT2MRI(ct)), ct)
loss_cycle = (loss_cycle_mri + loss_cycle_ct) * 0.5
```

**L√Ω do tr·ªçng s·ªë cao (Œª = 10.0)**:
- **Core constraint**: ƒê·∫£m b·∫£o t√≠nh consistency c∆° b·∫£n c·ªßa cycle
- **Prevent mode collapse**: NgƒÉn generator t·∫°o ra mapping t√πy √Ω
- **Medical accuracy**: ƒê·∫∑c bi·ªát quan tr·ªçng trong ·ª©ng d·ª•ng y t·∫ø
- **Empirical validation**: Gi√° tr·ªã 10.0 ƒë∆∞·ª£c verify qua nhi·ªÅu nghi√™n c·ª©u CycleGAN

**L1 vs L2 loss**:
- **L1 Loss**: √çt b·ªã blur h∆°n, preserve sharp edges t·ªët h∆°n
- **Robust to outliers**: Quan tr·ªçng v·ªõi medical images c√≥ noise

### 3. Identity Loss (Œª = 5.0)

**C√¥ng th·ª©c**:
```python
loss_identity_ct = F.l1_loss(G_MRI2CT(ct), ct)
loss_identity_mri = F.l1_loss(G_CT2MRI(mri), mri)
loss_identity = (loss_identity_ct + loss_identity_mri) * 0.5
```

**M·ª•c ƒë√≠ch**:
- **Color preservation**: Gi·ªØ nguy√™n t√¥ng m√†u khi input ƒë√£ ƒë√∫ng domain
- **Reduce overshoot**: Tr√°nh generator thay ƒë·ªïi qu√° m·ª©c kh√¥ng c·∫ßn thi·∫øt

**Tr·ªçng s·ªë Œª_identity = 5.0**:
- **Moderate constraint**: Kh√¥ng qu√° restrictive nh∆∞ cycle consistency
- **Medical consideration**: ƒê·∫£m b·∫£o intensity values ƒë∆∞·ª£c preserve ph√π h·ª£p
- **Half of cycle weight**: C√¢n b·∫±ng gi·ªØa consistency v√† flexibility

### 4. Perceptual Loss (Œª = 1.0)

**Ki·∫øn tr√∫c VGG19-based**:
```python
feature_layers = [3, 8, 15, 22]  # ReLU1_2, ReLU2_2, ReLU3_4, ReLU4_4
loss_perceptual = Œ£ MSE(VGG_i(fake_ct), VGG_i(real_ct))
```

**L√Ω do ch·ªçn VGG19**:
- **Pre-trained features**: ƒê√£ h·ªçc ƒë∆∞·ª£c generic visual patterns
- **Multi-scale representation**: T·ª´ low-level ƒë·∫øn high-level features
- **Medical imaging validation**: Hi·ªáu qu·∫£ ƒë√£ ƒë∆∞·ª£c ch·ª©ng minh v·ªõi medical images

**Feature layers selection**:
- **Layer 3 (ReLU1_2)**: Low-level textures, edges
- **Layer 8 (ReLU2_2)**: Medium-level patterns  
- **Layer 15 (ReLU3_4)**: High-level features
- **Layer 22 (ReLU4_4)**: Semantic representations

**Tr·ªçng s·ªë Œª_perceptual = 1.0**:
- **Complementary role**: B·ªï sung cho pixel-wise losses
- **Equal importance**: V·ªõi adversarial loss ƒë·ªÉ c√¢n b·∫±ng quality
- **Medical relevance**: ƒê·∫£m b·∫£o similarity ·ªü multiple perception levels

### 5. T·ªïng h·ª£p Loss Function

**Total Generator Loss**:
```python
L_total = Œª_adversarial √ó L_GAN + 
          Œª_cycle √ó L_cycle + 
          Œª_identity √ó L_identity + 
          Œª_perceptual √ó L_perceptual

L_total = 1.0 √ó L_GAN + 10.0 √ó L_cycle + 5.0 √ó L_identity + 1.0 √ó L_perceptual
```

**Hierarchy c·ªßa tr·ªçng s·ªë**:
1. **L_cycle (10.0)**: Highest priority - ƒë·∫£m b·∫£o consistency c∆° b·∫£n
2. **L_identity (5.0)**: Medium priority - preserve original characteristics  
3. **L_GAN (1.0)**: Standard priority - realistic generation
4. **L_perceptual (1.0)**: Standard priority - perceptual quality

**T√°c ƒë·ªông c·ªßa t·ª´ng th√†nh ph·∫ßn**:
- **Cycle consistency**: ƒê·∫£m b·∫£o mapping c√≥ th·ªÉ ƒë·∫£o ng∆∞·ª£c
- **Identity loss**: Gi·ªØ nguy√™n khi kh√¥ng c·∫ßn transform
- **Adversarial loss**: T·∫°o ra ·∫£nh realistic
- **Perceptual loss**: C·∫£i thi·ªán ch·∫•t l∆∞·ª£ng visual v√† texture

## üìà Metrics ƒê√°nh gi√°

### 1. Mean Absolute Error (MAE)
- **C√¥ng th·ª©c**: `MAE = (1/N) Œ£ |y_pred - y_true|`
- **√ù nghƒ©a**: Sai s·ªë trung b√¨nh tuy·ªát ƒë·ªëi, ƒë∆°n v·ªã gi·ªëng pixel intensity
- **T·∫ßm quan tr·ªçng**: ƒêo l∆∞·ªùng ƒë·ªô ch√≠nh x√°c pixel-level

### 2. Mean Squared Error (MSE)  
- **C√¥ng th·ª©c**: `MSE = (1/N) Œ£ (y_pred - y_true)¬≤`
- **√ù nghƒ©a**: Nh·∫•n m·∫°nh c√°c sai s·ªë l·ªõn, penalty cho outliers
- **S·ª≠ d·ª•ng**: ƒê√°nh gi√° overall reconstruction quality

### 3. Peak Signal-to-Noise Ratio (PSNR)
- **C√¥ng th·ª©c**: `PSNR = 20 √ó log‚ÇÅ‚ÇÄ(MAX_I / ‚àöMSE)`
- **ƒê∆°n v·ªã**: Decibel (dB)
- **Gi√° tr·ªã t·ªët**: >25 dB cho medical images
- **√ù nghƒ©a**: T·ª∑ l·ªá signal/noise, cao h∆°n = ch·∫•t l∆∞·ª£ng t·ªët h∆°n

### 4. Structural Similarity Index (SSIM)
- **Range**: [0, 1], c√†ng g·∫ßn 1 c√†ng t·ªët
- **Th√†nh ph·∫ßn**: Luminance √ó Contrast √ó Structure
- **∆Øu ƒëi·ªÉm**: T∆∞∆°ng quan t·ªët v·ªõi perception c·ªßa con ng∆∞·ªùi
- **Medical relevance**: Quan tr·ªçng cho texture v√† structural details

### 5. Normalized Cross Correlation (NCC)
- **Range**: [-1, 1], l√Ω t∆∞·ªüng l√† 1
- **√ù nghƒ©a**: ƒêo correlation gi·ªØa hai ·∫£nh
- **Robust**: Kh√¥ng b·ªã ·∫£nh h∆∞·ªüng b·ªüi linear intensity changes

## üöÄ H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng

### C√†i ƒë·∫∑t Dependencies

```bash
git clone <repository-url>
cd mri-to-ct
pip install -r requirements.txt
```

### Training

```bash
cd src
python train.py
```

**Tham s·ªë Training c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh**:
```python
config = {
    'batch_size': 4,          # T√πy thu·ªôc GPU memory
    'num_epochs': 200,        # ƒê·ªß ƒë·ªÉ converge
    'lr_G': 0.0002,          # Learning rate cho Generator
    'lr_D': 0.0002,          # Learning rate cho Discriminator  
    'decay_epoch': 100,       # B·∫Øt ƒë·∫ßu decay LR
    'decay_epochs': 100       # S·ªë epoch ƒë·ªÉ decay v·ªÅ 0
}
```

### Testing

#### Test m·ªôt ·∫£nh MRI ƒë∆°n l·∫ª:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode single \
               --mri_path data/MRI/brain_001.nii.gz \
               --output_dir results/
```

#### Test v·ªõi ground truth ƒë·ªÉ t√≠nh metrics:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode with_gt \
               --mri_path data/MRI/brain_001.nii.gz \
               --ct_path data/CT/brain_001.nii.gz \
               --output_dir results/
```

#### Test tr√™n to√†n b·ªô dataset:
```bash
python test.py --model_path checkpoints/best_model.pth \
               --test_mode dataset \
               --mri_dir data/Test/MRI \
               --ct_dir data/Test/CT \
               --output_dir results/
```

## üìÅ D·ªØ li·ªáu Input/Output

### D·ªØ li·ªáu ƒë·∫ßu v√†o
- **Format**: NIfTI (.nii.gz)
- **Naming convention**: brain_001.nii.gz ƒë·∫øn brain_046.nii.gz
- **Pairing**: M·ªói file MRI c√≥ file CT t∆∞∆°ng ·ª©ng c√πng t√™n
- **Preprocessing**: D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c c·∫Øt v√πng (cropped) th·ªß c√¥ng
- **Resolution**: T·ª± ƒë·ªông resize v·ªÅ 256√ó256 cho training

### K·∫øt qu·∫£ ƒë·∫ßu ra
- **Synthetic CT**: File .nii.gz v·ªõi suffix "_synthetic_ct"
- **Comparison images**: File .png hi·ªÉn th·ªã MRI input, CT m√¥ ph·ªèng, v√† difference map
- **Metrics report**: C√°c ch·ªâ s·ªë MAE, MSE, SSIM, PSNR, NCC
- **Tensorboard logs**: Theo d√µi loss v√† metrics qua epochs

## ‚öôÔ∏è Y√™u c·∫ßu H·ªá th·ªëng

### Hardware Requirements
- **GPU**: CUDA-enabled GPU v·ªõi √≠t nh·∫•t 8GB VRAM (khuy·∫øn ngh·ªã 16GB+)
- **RAM**: T·ªëi thi·ªÉu 16GB, khuy·∫øn ngh·ªã 32GB
- **Storage**: ~20GB cho d·ªØ li·ªáu, checkpoints v√† logs
- **CPU**: Multi-core processor ƒë·ªÉ data loading

### Software Requirements
- **Python**: 3.7+
- **PyTorch**: 1.9.0+
- **CUDA**: 11.0+ (n·∫øu s·ª≠ d·ª•ng GPU)
- **Operating System**: Linux (khuy·∫øn ngh·ªã), Windows, macOS

## üìä Monitoring v√† Debugging

### Tensorboard Monitoring
```bash
tensorboard --logdir logs/
```

**Metrics ƒë∆∞·ª£c track**:
- Training/Validation losses (G_total, G_gan, G_cycle, G_identity, G_perceptual)
- Discriminator losses (D_CT, D_MRI)
- Image quality metrics (MAE, MSE, SSIM, PSNR)
- Learning rates

### Sample Images
- **Frequency**: M·ªói 5 epochs
- **Location**: `samples/epoch_X/`
- **Content**: Real MRI, Fake CT, Real CT, Reconstructed images

### Checkpoint Strategy
- **Regular saves**: M·ªói 10 epochs
- **Best model**: D·ª±a tr√™n validation SSIM
- **Resume capability**: C√≥ th·ªÉ ti·∫øp t·ª•c training t·ª´ checkpoint

## üî¨ K·∫øt qu·∫£ Mong ƒë·ª£i

### Performance Benchmarks
- **SSIM**: >0.85 cho high-quality synthesis
- **PSNR**: >25 dB
- **MAE**: <0.1 (v·ªõi normalized intensity)
- **Training time**: 24-48 gi·ªù tr√™n GPU RTX 3080

### Qualitative Assessment
- **Bone structures**: R√µ n√©t v√† ch√≠nh x√°c trong CT m√¥ ph·ªèng
- **Soft tissue contrast**: T∆∞∆°ng ƒë·ªìng v·ªõi CT th·∫≠t
- **Artifacts**: T·ªëi thi·ªÉu noise v√† distortion
- **Anatomical consistency**: Gi·ªØ nguy√™n c·∫•u tr√∫c t·ª´ MRI

## ‚ö†Ô∏è L∆∞u √Ω Quan tr·ªçng

### Medical Applications
1. **Validation requirement**: K·∫øt qu·∫£ c·∫ßn ƒë∆∞·ª£c x√°c th·ª±c b·ªüi chuy√™n gia y t·∫ø
2. **Clinical responsibility**: Kh√¥ng s·ª≠ d·ª•ng tr·ª±c ti·∫øp m√† kh√¥ng c√≥ supervision
3. **Regulatory compliance**: Tu√¢n th·ªß c√°c quy ƒë·ªãnh y t·∫ø ƒë·ªãa ph∆∞∆°ng
4. **Quality assurance**: Ki·ªÉm tra k·ªπ l∆∞·ª°ng tr∆∞·ªõc khi s·ª≠ d·ª•ng l√¢m s√†ng

### Technical Considerations
1. **Data quality**: Ch·∫•t l∆∞·ª£ng input ·∫£nh h∆∞·ªüng tr·ª±c ti·∫øp ƒë·∫øn output
2. **Domain specificity**: Model ƒë∆∞·ª£c train cho brain images
3. **Generalization**: C·∫ßn validation v·ªõi different scanners/protocols
4. **Computational cost**: Training resource-intensive

### Hyperparameter Tuning
- **Learning rates**: C√≥ th·ªÉ c·∫ßn ƒëi·ªÅu ch·ªânh t√πy dataset
- **Loss weights**: Fine-tune d·ª±a tr√™n validation metrics
- **Architecture**: C√≥ th·ªÉ thay ƒë·ªïi s·ªë residual blocks
- **Training schedule**: ƒêi·ªÅu ch·ªânh decay timing

## üìö T√†i li·ªáu Tham kh·∫£o

### Core Papers
- **CycleGAN**: Zhu, J.Y., et al. "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks." ICCV 2017
- **Perceptual Loss**: Johnson, J., et al. "Perceptual Losses for Real-Time Style Transfer and Super-Resolution." ECCV 2016
- **PatchGAN**: Isola, P., et al. "Image-to-Image Translation with Conditional Adversarial Networks." CVPR 2017

### Medical Imaging References
- **MRI-CT Synthesis**: Lei, Y., et al. "MRI-only based synthetic CT generation using dense cycle consistent generative adversarial networks." Medical Physics 2019
- **N4 Bias Correction**: Tustison, N.J., et al. "N4ITK: improved N3 bias correction." IEEE TMI 2010

### Implementation Guides
- **README Best Practices**: [How to Write a Good README](https://www.freecodecamp.org/news/how-to-write-a-good-readme-file/)
- **Documentation Standards**: [Make a README](https://www.makeareadme.com/)

## ü§ù Contributing

### Development Guidelines
1. **Code style**: Follow PEP 8 conventions
2. **Documentation**: Comment all functions v√† classes
3. **Testing**: Add unit tests for new features
4. **Version control**: Use descriptive commit messages

### Bug Reports
- Include system specifications
- Provide error logs v√† stack traces
- Describe reproduction steps
- Attach sample data if possible

## üìÑ License

[Th√™m th√¥ng tin license ph√π h·ª£p]

## üë• Li√™n h·ªá

**Nh√≥m ph√°t tri·ªÉn**: MRI-to-CT Research Team
**Email**: [Th√™m email li√™n h·ªá]
**Institution**: [Th√™m th√¥ng tin t·ªï ch·ª©c]

---

**L∆∞u √Ω**: ƒê√¢y l√† d·ª± √°n nghi√™n c·ª©u. K·∫øt qu·∫£ c·∫ßn ƒë∆∞·ª£c validation v√† approval t·ª´ chuy√™n gia y t·∫ø tr∆∞·ªõc khi s·ª≠ d·ª•ng trong th·ª±c t·∫ø l√¢m s√†ng. 